# Anthropic API (leave blank for fully local Ollama-only mode)
ANTHROPIC_API_KEY=sk-ant-xxxxx
MIXAGENT_MODEL=claude-sonnet-4-20250514

# Ollama local LLM (used as fallback by default, or primary if no API key)
OLLAMA_HOST=http://localhost:11434
MIXAGENT_FALLBACK_MODEL=llama3:8b

# For fully local operation:
#   1. Leave ANTHROPIC_API_KEY blank (or delete the line)
#   2. Set ollama_primary: true in config/show.json
#   3. Run: ollama pull llama3:8b
#   4. Start ollama: ollama serve

MIXAGENT_LOG_LEVEL=info
